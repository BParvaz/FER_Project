{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b98997",
   "metadata": {},
   "source": [
    "# Precursors\n",
    "The current iteration of this pipeline is coded to work only for FER2013  \n",
    "Plans include room for RAFDB, CK+ and other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ad8f7",
   "metadata": {},
   "source": [
    "##### Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be00c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version:  2.5.1\n",
      "Numpy version:  2.2.5\n",
      "Jupyter notebook version:  7.1.0\n",
      "Timm version:  1.0.22\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ipykernel\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import timm\n",
    "print(\"Pytorch version: \",torch.__version__)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Jupyter notebook version: \",ipykernel.__version__)\n",
    "print(\"Timm version: \",timm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e150d",
   "metadata": {},
   "source": [
    "#### 1. Import data and wrap around dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174feeeb",
   "metadata": {},
   "source": [
    "##### Create FERDataset Class to store datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FERDataset\n",
    "A class which inherits the pytorch dataset for storing and manipulating our input\n",
    "\"\"\"\n",
    "# Inherits Pytorch dataset\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform = None):\n",
    "        # Constructor\n",
    "        # (String) df: Instance of pandas dataframe with data already loaded\n",
    "        # (Function) transform: Image processing function \n",
    "        \n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        pixels = np.fromstring(row['pixels'], sep=' ', dtype=np.uint8)\n",
    "        img = pixels.reshape(48, 48) #48x48 to match FER2013\n",
    "\n",
    "        # from greyscale to RGB\n",
    "        img = Image.fromarray(img).convert(\"RGB\")\n",
    "\n",
    "        label = int(row['emotion'])\n",
    "\n",
    "        # transform img\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        classes = self.df['emotion'].unique()\n",
    "        classes.sort()\n",
    "        return classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6673b52c",
   "metadata": {},
   "source": [
    "##### Load and test the dataset (FER2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "549457af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer2013_dataframe = pandas.read_csv('C:\\\\Users\\\\Bahram\\\\Desktop\\\\Personal Projects\\\\FER Tinkering\\\\From_Scratch\\\\data\\\\FER2013\\\\fer2013.csv')\n",
    "dataset = FERDataset(dataframe=fer2013_dataframe)\n",
    "dataset.classes\n",
    "# Should be seven classes for FER2013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8dbb2",
   "metadata": {},
   "source": [
    "##### Class dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6992bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_names = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa504e94",
   "metadata": {},
   "source": [
    "##### Grab an image and check its emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fef9adf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAwADADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCXRoDb2pQHDyHe59a2ELBPl+761mWsoE7cYGKW78Q29gwgZZGJ5+VcigDVDE5DdajkMagbsGsq31yO/vJIoMnZGdwKkFT71mya9K0bBVhEkKjzDO+wDnHHqfYUAdKskfzbCQe4HpXL6vDaamrRSqN2Nu7HSm/8JFDEHWa7t1mWTYPLztbr8wb04x+IqhLeRyhpgw38uVzzj6UAXbe+aVGc5VSAVYI368dM01PD91ervjuZY33ZeSFFGfbLcjHtWxpc9vIwYqMAAAAdAO1bcKx7XEKZUn5snFAHO6bYSWd5sd3ZChMrsxzI3Y5rC+ywJr08b2yyKWygOeAev1rrb+9tbe7cXEgT5cgL7Vy9/rum3WowpCymRB1zgkZ/mKAJ9R8M287iZIojIRyRCAx+tZ0+gtAi/bM/MOdjYx9K6xruNtP82NiTj7pbI/CuW1C8uLmP7rYHAJoA09GBMkTEkmSMMxxjnv8ArXTJMYrdgn3icLmuVs9a026e2ltbqNmOR5W3awHU5HtW2JS6eZF8xQ5xQBn3vhOx1HUEurqSaQxqRt3EAk96zJvBWn2lyjwB1ON2WOT+fpWlLHqd4M3N59ihPISEZJ9y39BWXc2EJdpHvdQkfs3mdfwFAFuGOW1wpwyN6HNF7IhgCgDiqen2xivIjPeTFAeEcj8KpalfotzNgjCkgUAf/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = dataset[123]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84dd77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Angry'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_names[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23463bee",
   "metadata": {},
   "source": [
    "### I don't think he looks angry, but moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971334a",
   "metadata": {},
   "source": [
    "##### 2. Transform each image and recreate the dataset using the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fbfe249",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = FERDataset(fer2013_dataframe, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7f1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "image.shape # Three channels, 48x48 image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880de4e",
   "metadata": {},
   "source": [
    "##### Dataloaders  \n",
    "For batching our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c7c60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset,batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Self_Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
